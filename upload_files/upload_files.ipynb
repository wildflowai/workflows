{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# VUE to **wildflow**\n",
        "\n",
        "Loads acoustic tag data (downloaded from VUE software) to [**wildflow**](https://wildflow.ai).\n",
        "\n",
        "<img src=\"https://wildflow.ai/_next/static/media/whale.22046cae.jpg\" width=\"300\">\n"
      ],
      "metadata": {
        "id": "E4BkCHE0qQVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 1. Setup your project details\n",
        "\n",
        "- Please make sure that the details below are correct;\n",
        "- And then run the cell:\n"
      ],
      "metadata": {
        "id": "TEYzhnMdwJjl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk12ureGp_s9"
      },
      "outputs": [],
      "source": [
        "project = 'wildflow-pelagic' #@param {type: \"string\"}\n",
        "path = 'pelagioskakunja/provided-data' #@param {type: \"string\"}\n",
        "\n",
        "print('Your files will be stored here:\\n'+ f'https://console.cloud.google.com/storage/browser/{path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 2. [Optional] Load files from your computer to **wildflow** bucket."
      ],
      "metadata": {
        "id": "8h4BsUnXxDx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-cloud-storage\n",
        "\n",
        "from google.colab import files, auth\n",
        "from google.cloud import storage\n",
        "from IPython.display import display, Markdown, HTML\n",
        "import os\n",
        "\n",
        "# Authenticate with GCP\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Initialize the GCS client\n",
        "client = storage.Client(project=project)\n",
        "bucket_name, folder_path = path.split('/', 1)\n",
        "bucket = client.get_bucket(bucket_name)\n",
        "\n",
        "# Upload files\n",
        "uploaded = files.upload()\n",
        "\n",
        "uploaded_gcs_paths = []\n",
        "for fn, content in uploaded.items():\n",
        "    blob = bucket.blob(f'{folder_path}/{fn}')\n",
        "    blob.upload_from_string(content)\n",
        "    uploaded_gcs_paths.append(f\"gs://{bucket_name}/{folder_path}/{fn}\")\n",
        "    # Remove the file from the local Colab environment\n",
        "    os.remove(fn)\n",
        "\n",
        "# Display uploaded file paths\n",
        "display(Markdown(\"### Uploaded Files:\"))\n",
        "for file_path in uploaded_gcs_paths:\n",
        "    display(Markdown(f\"- {file_path}\"))\n",
        "\n",
        "# Generate and display the GCS link\n",
        "gcs_link = f'https://console.cloud.google.com/storage/browser/{path}'\n",
        "display(HTML(f'Your files have been stored <a href=\"{gcs_link}\" target=\"_blank\">here</a>.'))\n"
      ],
      "metadata": {
        "id": "Y-AnOTAgufNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load VUE file from the bucket to **wildflow** BigQuery."
      ],
      "metadata": {
        "id": "FgBKUFMU6s5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'pelagioskakunja/provided-data/C.Leucas_Caribe_Sergei.csv' #@param {type: \"string\"}\n",
        "tablename = 'wildflow-pelagic.env.new_table' #@param {type: \"string\"}\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Standard schema fro VUE files.\n",
        "schema = [\n",
        "    {\"name\": \"row_id\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"x1\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"x\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"date_and_time_utc\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"receiver\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"transmitter\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"transmitter_name\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"transmitter_serial\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"sensor_value\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"sensor_unit\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"station_name\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"latitude\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"longitude\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"transmitter_type\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"sensor_precision\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"latitude_2\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"},\n",
        "    {\"name\": \"longitude_2\", \"type\": \"STRING\", \"mode\": \"NULLABLE\"}\n",
        "]\n",
        "\n",
        "project_id, dataset_id, table_id = tablename.split('.')\n",
        "client = bigquery.Client(project=project_id)\n",
        "dataset_ref = client.dataset(dataset_id)\n",
        "table_ref = dataset_ref.table(table_id)\n",
        "\n",
        "job_config = bigquery.LoadJobConfig()\n",
        "job_config.source_format = bigquery.SourceFormat.CSV\n",
        "job_config.skip_leading_rows = 1\n",
        "job_config.schema = [\n",
        "    bigquery.SchemaField(field[\"name\"], field[\"type\"], mode=field[\"mode\"]) for field in schema\n",
        "]\n",
        "\n",
        "uri = f\"gs://{filename}\"\n",
        "load_job = client.load_table_from_uri(uri, table_ref, job_config=job_config)\n",
        "load_job.result()\n",
        "\n",
        "print(f\"Loaded {load_job.output_rows} rows into {dataset_id}:{table_id}.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Jc1n75n__B16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = \"\"\"\n",
        "SELECT latitude, longitude, COUNT(*) as rows_count\n",
        "FROM `{}`\n",
        "GROUP BY 1, 2\n",
        "\"\"\".format(tablename)\n",
        "\n",
        "df = client.query(sql).to_dataframe()\n",
        "\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "SCUPINPoCD8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "\n",
        "df['latitude'] = df['latitude'].astype(float)\n",
        "df['longitude'] = df['longitude'].astype(float)\n",
        "m = folium.Map(location=[df['latitude'].mean(), df['longitude'].mean()], zoom_start=10)\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=(row['latitude'], row['longitude']),\n",
        "        radius=5,\n",
        "        fill=True,\n",
        "        color='blue',\n",
        "        fill_color='blue',\n",
        "        fill_opacity=0.6\n",
        "    ).add_to(m)\n",
        "\n",
        "m"
      ],
      "metadata": {
        "id": "e0Cb4VXPC7vl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}